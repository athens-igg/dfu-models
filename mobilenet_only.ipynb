{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPAcr4dUDK90hLRXmeTcmG3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athens-igg/dfu-models/blob/main/mobilenet_only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39KlkKFZgN7M"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install tensorflow\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()   # select kaggle.json"
      ],
      "metadata": {
        "id": "r-t5PbYggVHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp \"kaggle (13).json\" ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "w1OcnLVLggNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d purushomohan/dfu-wagners-classification"
      ],
      "metadata": {
        "id": "Uv1RYG5ngkKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n"
      ],
      "metadata": {
        "id": "iK3NCqcIgnxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!unzip -q dfu-wagners-classification.zip -d /content/drive"
      ],
      "metadata": {
        "id": "VK6zNY3Bgy34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data=\"/content/drive/Dataset/Training\"\n",
        "valid_data=\"/content/drive/Dataset/Validation\""
      ],
      "metadata": {
        "id": "zNZk3n8Fg1lI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "N_CLASSES = 5   # Wagner 0–4 (adjust if you have normal + ulcer separately)\n",
        "\n",
        "# ============================\n",
        "# 1) Data Preprocessing & Augmentation\n",
        "# ============================\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_data,  # path to training dataset\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    valid_data,  # path to validation dataset\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "# ============================\n",
        "# 2) Define MobileNetV2 Model\n",
        "# ============================\n",
        "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze base model for transfer learning\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "output = Dense(N_CLASSES, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# ============================\n",
        "# 3) Compile\n",
        "# ============================\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# 4) Callbacks\n",
        "# ============================\n",
        "checkpoint = ModelCheckpoint(\n",
        "    \"/content/drive/Dataset/best_model.h5\",\n",
        "    monitor=\"val_loss\",   # or \"val_loss\" if you prefer\n",
        "    save_best_only=True,\n",
        "    mode=\"min\"\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5, verbose=1),\n",
        "    checkpoint\n",
        "]\n",
        "\n",
        "\n",
        "# ============================\n",
        "# 5) Train\n",
        "# ============================\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# 6) Fine-tune (optional)\n",
        "# ============================\n",
        "# Unfreeze some top layers\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-30]:  # keep earlier layers frozen\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history_ft = model.fit(\n",
        "    train_gen,\n",
        "    epochs=50,\n",
        "    validation_data=val_gen,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "metadata": {
        "id": "G5ROiqpdg_hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the best model saved by ModelCheckpoint\n",
        "best_model = load_model(\"/content/drive/Dataset/best_model.h5\")\n",
        "\n",
        "# Evaluate on validation data\n",
        "val_loss, val_acc = best_model.evaluate(val_gen)\n",
        "print(f\"Best Validation Accuracy: {val_acc*100:.2f}%\")\n",
        "print(f\"Best Validation Loss: {val_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "DDqBfFFth7eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Merge history and fine-tuning history\n",
        "acc = history.history['accuracy'] + history_ft.history['accuracy']\n",
        "val_acc = history.history['val_accuracy'] + history_ft.history['val_accuracy']\n",
        "loss = history.history['loss'] + history_ft.history['loss']\n",
        "val_loss = history.history['val_loss'] + history_ft.history['val_loss']\n",
        "\n",
        "epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "# Plot accuracy\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training vs Validation Accuracy (with Fine-tuning)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training vs Validation Loss (with Fine-tuning)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "debJcBM9iH_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/Dataset/best_model.h5')"
      ],
      "metadata": {
        "id": "_whhKsywiL13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/drive/Dataset/best_model.h5')"
      ],
      "metadata": {
        "id": "hOLqAW6Qiz03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless\n",
        "from google.colab import files\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Upload image\n",
        "uploaded = files.upload()\n",
        "class_names = [\"Grade 0\", \"Grade1\", \"Grade2\", \"Grade3\", \"Normal\" ]\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "true_class_name = \"Grade 0\"  # change based on the image you uploaded\n",
        "true_class_id = class_names.index(true_class_name)\n",
        "\n",
        "\n",
        "# Load and preprocess image\n",
        "IMG_SIZE = (224, 224)\n",
        "img = cv2.imread(filename)\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_resized = cv2.resize(img_rgb, IMG_SIZE)\n",
        "\n",
        "# Normalize same as training (rescale 1/255)\n",
        "img_array = img_resized.astype(\"float32\") / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # add batch dimension\n",
        "# Predict\n",
        "pred = best_model.predict(img_array)\n",
        "class_id = np.argmax(pred)\n",
        "confidence = np.max(pred)\n",
        "\n",
        "# Show result\n",
        "plt.imshow(img_rgb)\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"Prediction: {class_names[class_id]} ({confidence*100:.2f}%)\")\n",
        "plt.show()\n",
        "\n",
        "if class_id == true_class_id:\n",
        "    print(\"Correctly classified\")\n",
        "else:\n",
        "    print(\"Misclassified\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Jbg_lU-itx7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Upload the image\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # This will open a file picker\n",
        "\n",
        "# Get the uploaded file path\n",
        "img_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Load and preprocess the uploaded image\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Read the image\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Resize to your model's expected input size (replace 224 with your size)\n",
        "img_resized = cv2.resize(img, (224, 224))\n",
        "\n",
        "# Normalize if your model was trained with normalized images\n",
        "input_array = np.expand_dims(img_resized / 255.0, axis=0)\n",
        "\n",
        "# input_array is now ready for Grad-CAM\n"
      ],
      "metadata": {
        "id": "HLJlKFw3uvGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load model\n",
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/drive/Dataset/best_model.h5')\n",
        "\n",
        "# Step 2: Load and preprocess uploaded image\n",
        "import cv2\n",
        "import numpy as np\n",
        "#img_path = \"Screenshot 2025-12-28 170002 (1).png\"  # your uploaded file\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_resized = cv2.resize(img, (224, 224))  # replace 224 with your model input size\n",
        "input_array = np.expand_dims(img_resized / 255.0, axis=0)  # normalize if needed\n",
        "\n",
        "# Step 3: Identify last convolutional layer\n",
        "last_conv_layer_name = None\n",
        "for layer in model.layers[::-1]:\n",
        "    if 'conv' in layer.name:\n",
        "        last_conv_layer_name = layer.name\n",
        "        break\n",
        "print(\"Last convolutional layer:\", last_conv_layer_name)\n",
        "\n",
        "# Step 4: Grad-CAM heatmap generation\n",
        "import tensorflow as tf\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        class_idx = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, class_idx]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # Normalize heatmap from 0 to 1 for color mapping\n",
        "    heatmap = heatmap - tf.reduce_min(heatmap)\n",
        "    heatmap = heatmap / tf.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "heatmap = make_gradcam_heatmap(input_array, model, last_conv_layer_name)\n",
        "\n",
        "# Step 5: Overlay heatmap on original image with clear blue → red gradient\n",
        "heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "heatmap_resized = np.uint8(255 * heatmap_resized)\n",
        "heatmap_color = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)  # Jet: blue=low, red=high\n",
        "superimposed_img = cv2.addWeighted(img, 0.6, heatmap_color, 0.4, 0)\n",
        "\n",
        "# Step 6: Display Grad-CAM\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(superimposed_img)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Optional: save the Grad-CAM image\n",
        "cv2.imwrite(\"gradcam_output.png\", cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))\n",
        "print(\"Grad-CAM saved as gradcam_output.png\")\n",
        "\n"
      ],
      "metadata": {
        "id": "c19dRTFIw94u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install LIME\n",
        "!pip install lime\n",
        "\n",
        "# Step 2: Load model and image\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "model = keras.models.load_model('/content/drive/Dataset/best_model.h5')\n",
        "\n",
        "# Load uploaded image\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_resized = cv2.resize(img, (224, 224))\n",
        "input_array = np.expand_dims(img_resized / 255.0, axis=0)\n",
        "\n",
        "# Step 3: LIME setup\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import slic\n",
        "\n",
        "explainer = lime_image.LimeImageExplainer()\n",
        "\n",
        "# Define prediction function for LIME\n",
        "def predict_fn(images):\n",
        "    images = np.array(images) / 255.0  # normalize\n",
        "    return model.predict(images)\n",
        "\n",
        "# Step 4: Generate explanation\n",
        "explanation = explainer.explain_instance(\n",
        "    img_resized,                   # original image\n",
        "    predict_fn,                    # prediction function\n",
        "    top_labels=1,                  # explain top predicted class\n",
        "    hide_color=0,\n",
        "    num_samples=1000               # increase for smoother explanation\n",
        ")\n",
        "\n",
        "# Step 5: Get image and mask for top class\n",
        "from skimage.color import label2rgb\n",
        "\n",
        "top_label = explanation.top_labels[0]\n",
        "temp, mask = explanation.get_image_and_mask(\n",
        "    top_label,\n",
        "    positive_only=False,\n",
        "    num_features=10,\n",
        "    hide_rest=False\n",
        ")\n",
        "img_boundry = label2rgb(mask, temp, bg_label=0)\n",
        "\n",
        "# Step 6: Display and save explanation\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(img_boundry)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Save the LIME overlay\n",
        "from matplotlib import image as mpimg\n",
        "mpimg.imsave(\"lime_output.png\", img_boundry)\n",
        "print(\"LIME overlay saved as lime_output.png\")\n"
      ],
      "metadata": {
        "id": "1wxQdV_K2-y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless\n",
        "from google.colab import files\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Load the model\n",
        "model = keras.models.load_model('/content/drive/Dataset/best_model.h5')\n",
        "# Upload image\n",
        "uploaded = files.upload()\n",
        "class_names = [\"Grade 0\", \"Grade 1\", \"Grade 2\", \"Grade 3\", \"Normal\" ]\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "true_class_name = \"Grade 2\"  # change based on the image you uploaded\n",
        "true_class_id = class_names.index(true_class_name)\n",
        "\n",
        "\n",
        "# Load and preprocess image\n",
        "IMG_SIZE = (224, 224)\n",
        "img = cv2.imread(filename)\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_resized = cv2.resize(img_rgb, IMG_SIZE)\n",
        "\n",
        "# Normalize same as training (rescale 1/255)\n",
        "img_array = img_resized.astype(\"float32\") / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # add batch dimension\n",
        "# Predict\n",
        "pred = model.predict(img_array)\n",
        "class_id = np.argmax(pred)\n",
        "confidence = np.max(pred)\n",
        "\n",
        "# Show result\n",
        "plt.imshow(img_rgb)\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"Prediction: {class_names[class_id]} ({confidence*100:.2f}%)\")\n",
        "plt.show()\n",
        "\n",
        "if class_id == true_class_id:\n",
        "    print(\"Correctly classified\")\n",
        "else:\n",
        "    print(\"Misclassified\")\n",
        "\n"
      ],
      "metadata": {
        "id": "-04Q-9lJuviM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Upload the image\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # This will open a file picker\n",
        "\n",
        "# Get the uploaded file path\n",
        "img_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Load and preprocess the uploaded image\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Read the image\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Resize to your model's expected input size (replace 224 with your size)\n",
        "img_resized = cv2.resize(img, (224, 224))\n",
        "\n",
        "# Normalize if your model was trained with normalized images\n",
        "input_array = np.expand_dims(img_resized / 255.0, axis=0)\n",
        "\n",
        "# input_array is now ready for Grad-CAM\n"
      ],
      "metadata": {
        "id": "mREZPGux6oLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load model\n",
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/drive/Dataset/best_model.h5')\n",
        "\n",
        "# Step 2: Load and preprocess uploaded image\n",
        "import cv2\n",
        "import numpy as np\n",
        "#img_path = \"Screenshot 2025-12-28 170002 (1).png\"  # your uploaded file\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_resized = cv2.resize(img, (224, 224))  # replace 224 with your model input size\n",
        "input_array = np.expand_dims(img_resized / 255.0, axis=0)  # normalize if needed\n",
        "\n",
        "# Step 3: Identify last convolutional layer\n",
        "last_conv_layer_name = None\n",
        "for layer in model.layers[::-1]:\n",
        "    if 'conv' in layer.name:\n",
        "        last_conv_layer_name = layer.name\n",
        "        break\n",
        "print(\"Last convolutional layer:\", last_conv_layer_name)\n",
        "\n",
        "# Step 4: Grad-CAM heatmap generation\n",
        "import tensorflow as tf\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        class_idx = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, class_idx]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # Normalize heatmap from 0 to 1 for color mapping\n",
        "    heatmap = heatmap - tf.reduce_min(heatmap)\n",
        "    heatmap = heatmap / tf.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "heatmap = make_gradcam_heatmap(input_array, model, last_conv_layer_name)\n",
        "\n",
        "# Step 5: Overlay heatmap on original image with clear blue → red gradient\n",
        "heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "heatmap_resized = np.uint8(255 * heatmap_resized)\n",
        "heatmap_color = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)  # Jet: blue=low, red=high\n",
        "superimposed_img = cv2.addWeighted(img, 0.6, heatmap_color, 0.4, 0)\n",
        "\n",
        "# Step 6: Display Grad-CAM\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(superimposed_img)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Optional: save the Grad-CAM image\n",
        "cv2.imwrite(\"gradcam_output.png\", cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))\n",
        "print(\"Grad-CAM saved as gradcam_output.png\")\n",
        "\n"
      ],
      "metadata": {
        "id": "gk9aX5nC6dZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install LIME\n",
        "!pip install lime\n",
        "\n",
        "# Step 2: Load model and image\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "model = keras.models.load_model('/content/drive/Dataset/best_model.h5')\n",
        "\n",
        "# Load uploaded image\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_resized = cv2.resize(img, (224, 224))\n",
        "input_array = np.expand_dims(img_resized / 255.0, axis=0)\n",
        "\n",
        "# Step 3: LIME setup\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import slic\n",
        "\n",
        "explainer = lime_image.LimeImageExplainer()\n",
        "\n",
        "# Define prediction function for LIME\n",
        "def predict_fn(images):\n",
        "    images = np.array(images) / 255.0  # normalize\n",
        "    return model.predict(images)\n",
        "\n",
        "# Step 4: Generate explanation\n",
        "explanation = explainer.explain_instance(\n",
        "    img_resized,                   # original image\n",
        "    predict_fn,                    # prediction function\n",
        "    top_labels=1,                  # explain top predicted class\n",
        "    hide_color=0,\n",
        "    num_samples=1000               # increase for smoother explanation\n",
        ")\n",
        "\n",
        "# Step 5: Get image and mask for top class\n",
        "from skimage.color import label2rgb\n",
        "\n",
        "top_label = explanation.top_labels[0]\n",
        "temp, mask = explanation.get_image_and_mask(\n",
        "    top_label,\n",
        "    positive_only=False,\n",
        "    num_features=10,\n",
        "    hide_rest=False\n",
        ")\n",
        "img_boundry = label2rgb(mask, temp, bg_label=0)\n",
        "\n",
        "# Step 6: Display and save explanation\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(img_boundry)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Save the LIME overlay\n",
        "from matplotlib import image as mpimg\n",
        "mpimg.imsave(\"lime_output.png\", img_boundry)\n",
        "print(\"LIME overlay saved as lime_output.png\")\n"
      ],
      "metadata": {
        "id": "1rjLlT67-bgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless\n",
        "from google.colab import files\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Load the model\n",
        "model = keras.models.load_model('/content/drive/Dataset/best_model.h5')\n",
        "# Upload image\n",
        "uploaded = files.upload()\n",
        "class_names = [\"Grade 0\", \"Grade 1\", \"Grade 2\", \"Grade 3\", \"Normal\" ]\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "true_class_name = \"Grade 3\"  # change based on the image you uploaded\n",
        "true_class_id = class_names.index(true_class_name)\n",
        "\n",
        "\n",
        "# Load and preprocess image\n",
        "IMG_SIZE = (224, 224)\n",
        "img = cv2.imread(filename)\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_resized = cv2.resize(img_rgb, IMG_SIZE)\n",
        "\n",
        "# Normalize same as training (rescale 1/255)\n",
        "img_array = img_resized.astype(\"float32\") / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # add batch dimension\n",
        "# Predict\n",
        "pred = model.predict(img_array)\n",
        "class_id = np.argmax(pred)\n",
        "confidence = np.max(pred)\n",
        "\n",
        "# Show result\n",
        "plt.imshow(img_rgb)\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"Prediction: {class_names[class_id]} ({confidence*100:.2f}%)\")\n",
        "plt.show()\n",
        "\n",
        "if class_id == true_class_id:\n",
        "    print(\"Correctly classified\")\n",
        "else:\n",
        "    print(\"Misclassified\")\n",
        "\n"
      ],
      "metadata": {
        "id": "W6jiwPzW_vD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Upload the image\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # This will open a file picker\n",
        "\n",
        "# Get the uploaded file path\n",
        "img_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Load and preprocess the uploaded image\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Read the image\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Resize to your model's expected input size (replace 224 with your size)\n",
        "img_resized = cv2.resize(img, (224, 224))\n",
        "\n",
        "# Normalize if your model was trained with normalized images\n",
        "input_array = np.expand_dims(img_resized / 255.0, axis=0)\n",
        "\n",
        "# input_array is now ready for Grad-CAM\n"
      ],
      "metadata": {
        "id": "7PjYxWJ8_2zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load model\n",
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/drive/Dataset/best_model.h5')\n",
        "\n",
        "# Step 2: Load and preprocess uploaded image\n",
        "import cv2\n",
        "import numpy as np\n",
        "#img_path = \"Screenshot 2025-12-28 170002 (1).png\"  # your uploaded file\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_resized = cv2.resize(img, (224, 224))  # replace 224 with your model input size\n",
        "input_array = np.expand_dims(img_resized / 255.0, axis=0)  # normalize if needed\n",
        "\n",
        "# Step 3: Identify last convolutional layer\n",
        "last_conv_layer_name = None\n",
        "for layer in model.layers[::-1]:\n",
        "    if 'conv' in layer.name:\n",
        "        last_conv_layer_name = layer.name\n",
        "        break\n",
        "print(\"Last convolutional layer:\", last_conv_layer_name)\n",
        "\n",
        "# Step 4: Grad-CAM heatmap generation\n",
        "import tensorflow as tf\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        class_idx = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, class_idx]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # Normalize heatmap from 0 to 1 for color mapping\n",
        "    heatmap = heatmap - tf.reduce_min(heatmap)\n",
        "    heatmap = heatmap / tf.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "heatmap = make_gradcam_heatmap(input_array, model, last_conv_layer_name)\n",
        "\n",
        "# Step 5: Overlay heatmap on original image with clear blue → red gradient\n",
        "heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "heatmap_resized = np.uint8(255 * heatmap_resized)\n",
        "heatmap_color = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)  # Jet: blue=low, red=high\n",
        "superimposed_img = cv2.addWeighted(img, 0.6, heatmap_color, 0.4, 0)\n",
        "\n",
        "# Step 6: Display Grad-CAM\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(superimposed_img)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Optional: save the Grad-CAM image\n",
        "cv2.imwrite(\"gradcam_output.png\", cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))\n",
        "print(\"Grad-CAM saved as gradcam_output.png\")\n",
        "\n"
      ],
      "metadata": {
        "id": "dGWS0KEk_4VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load your model\n",
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/drive/Dataset/best_model.h5')\n",
        "\n",
        "# Step 2: Prepare the uploaded image\n",
        "import cv2\n",
        "import numpy as np\n",
        "#img_path = \"Screenshot 2025-12-28 170002 (1).png\"  # your uploaded file\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_resized = cv2.resize(img, (224, 224))  # replace 224 with your model input size\n",
        "input_array = np.expand_dims(img_resized / 255.0, axis=0)  # normalize if needed\n",
        "\n",
        "# Step 3: Identify last conv layer\n",
        "last_conv_layer_name = None\n",
        "for layer in model.layers[::-1]:\n",
        "    if 'conv' in layer.name:\n",
        "        last_conv_layer_name = layer.name\n",
        "        break\n",
        "print(\"Last convolutional layer:\", last_conv_layer_name)\n",
        "\n",
        "# Step 4: Generate Grad-CAM heatmap\n",
        "import tensorflow as tf\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        class_idx = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, class_idx]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "heatmap = make_gradcam_heatmap(input_array, model, last_conv_layer_name)\n",
        "\n",
        "# Step 5: Overlay heatmap on original image\n",
        "heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "heatmap_resized = np.uint8(255 * heatmap_resized)\n",
        "heatmap_color = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
        "superimposed_img = cv2.addWeighted(img, 0.6, heatmap_color, 0.4, 0)\n",
        "\n",
        "# Step 6: Display Grad-CAM\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(superimposed_img)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "D37KTAyYA27l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install LIME\n",
        "!pip install lime\n",
        "\n",
        "# Step 2: Load model and image\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "model = keras.models.load_model('/content/drive/Dataset/best_model.h5')\n",
        "\n",
        "# Load uploaded image\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_resized = cv2.resize(img, (224, 224))\n",
        "input_array = np.expand_dims(img_resized / 255.0, axis=0)\n",
        "\n",
        "# Step 3: LIME setup\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import slic\n",
        "\n",
        "explainer = lime_image.LimeImageExplainer()\n",
        "\n",
        "# Define prediction function for LIME\n",
        "def predict_fn(images):\n",
        "    images = np.array(images) / 255.0  # normalize\n",
        "    return model.predict(images)\n",
        "\n",
        "# Step 4: Generate explanation\n",
        "explanation = explainer.explain_instance(\n",
        "    img_resized,                   # original image\n",
        "    predict_fn,                    # prediction function\n",
        "    top_labels=1,                  # explain top predicted class\n",
        "    hide_color=0,\n",
        "    num_samples=1000               # increase for smoother explanation\n",
        ")\n",
        "\n",
        "# Step 5: Get image and mask for top class\n",
        "from skimage.color import label2rgb\n",
        "\n",
        "top_label = explanation.top_labels[0]\n",
        "temp, mask = explanation.get_image_and_mask(\n",
        "    top_label,\n",
        "    positive_only=False,\n",
        "    num_features=10,\n",
        "    hide_rest=False\n",
        ")\n",
        "img_boundry = label2rgb(mask, temp, bg_label=0)\n",
        "\n",
        "# Step 6: Display and save explanation\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(img_boundry)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Save the LIME overlay\n",
        "from matplotlib import image as mpimg\n",
        "mpimg.imsave(\"lime_output.png\", img_boundry)\n",
        "print(\"LIME overlay saved as lime_output.png\")\n"
      ],
      "metadata": {
        "id": "vXFKFY8v_6Uc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}